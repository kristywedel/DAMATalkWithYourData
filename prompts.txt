Prompt 1: Setting Up the Data Layer (setup_database.py)
Create setup_database.py, a script that:

Loads products and relationships from data.json.
Creates a SQLite database (products.db) with:
A products table (name, description, category).
A relationships table (entity1, relationship, entity2).
Inserts data dynamically, replacing duplicates.
Prints a confirmation message when setup is complete.

Prompt 2: app.py
Create a FastAPI-based product chatbot API that integrates a database search and a locally hosted LLM. The API should:

Use FastAPI with CORS middleware.
Have endpoints:
GET / returning a simple HTML message.
POST /chat accepting a user query, redacting PII using Presidio, performing a database search (SQLite, FAISS), and generating a response using an external LLM module.
Separate concerns:
Database search in database_search.py, using SQLite, FAISS, and relationship-based retrieval.
LLM processing in llm_model.py, loading a GGUF-based Llama-2-7B-Chat model via ctransformers and generating responses.
Use Pydantic models for request/response validation.
Run locally on 127.0.0.1:5000 with uvicorn, supporting live reload.
Ensure error handling for missing data or model issues.
Follow best practices for modularity and maintainability.

Prompt 3: Creating the Chat Interface (index.html)
Create index.html, a simple chat interface that:

Lets users ask queries via a chatbox.
Sends requests to http://127.0.0.1:5000/chat using fetch().
Displays chatbot responses dynamically.
Uses CSS for styling.
Maintains chat history.
Supports "Enter" key submission.
Handles errors if the API is unavailable.


Prompt 4: Validation Prompt
Create a validation script (validate_chatbot.py) that:

Ensures the chatbot API (app.py) runs correctly using FastAPI and Uvicorn.
Confirms FAISS is initialized properly and can return relevant products from data.json.
Validates SQLite (products.db) has expected tables (products and relationships) and is populated.
Checks if the LLM is loaded and responding.
Verifies /chat endpoint behavior by:
Sending test queries and confirming responses.
Ensuring FAISS returns semantic matches for vague queries.
Checking SQLite for exact lookup queries.
Running recursive SQL queries to validate relationship-based responses.
Ensuring the LLM generates a contextual response from aggregated data.
Validates session management by checking conversation_history.
Verifies CORS is enabled for frontend interaction.
Outputs a detailed validation report, logging errors if any steps fail.